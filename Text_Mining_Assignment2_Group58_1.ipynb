{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R90BRumRatVO"
      },
      "source": [
        "# Text Mining - Assignment 2: Sequence Labelling\n",
        "## Group 58: Vasiliki Gkika, Pelagia Kalpakidou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdi-ugi6atVS",
        "outputId": "6e95d6b0-e86c-41cf-9cb5-d0b16fbd6c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.12.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!apt install git-lfs\n",
        "import re\n",
        "import datasets\n",
        "from datasets import DatasetDict\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mK-eLl3atVU"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MZucUChSatVZ"
      },
      "outputs": [],
      "source": [
        "# load data and convert IOB file to correct data structure\n",
        "def read_datasets(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        raw_text = file.read().strip()\n",
        "\n",
        "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
        "    token_docs = []\n",
        "    tag_docs = []\n",
        "\n",
        "    for doc in raw_docs:\n",
        "        tokens = []\n",
        "        tags = []\n",
        "        for line in doc.split('\\n'):\n",
        "            if len(line.split('\\t')) < 2:\n",
        "                continue\n",
        "            token, tag = line.split('\\t')\n",
        "            tokens.append(token)\n",
        "            tags.append(tag)\n",
        "        token_docs.append(tokens)\n",
        "        tag_docs.append(tags)\n",
        "\n",
        "    return token_docs, tag_docs\n",
        "\n",
        "tokens_train, tag_train = read_datasets('wnut17train.conll')\n",
        "tokens_dev, tag_dev = read_datasets('emerging.dev.conll')\n",
        "tokens_test, tag_test = read_datasets('emerging.test.annotated')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQTrJeR1atVe"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RJGpgfnXatVi"
      },
      "outputs": [],
      "source": [
        "# map IOB tags to NER tags\n",
        "mapping = {\n",
        "        'O': 0,\n",
        "        'B-corporation': 1,\n",
        "        'I-corporation': 2,\n",
        "        'B-creative-work': 3,\n",
        "        'I-creative-work': 4,\n",
        "        'B-group': 5,\n",
        "        'I-group': 6,\n",
        "        'B-location': 7,\n",
        "        'I-location': 8,\n",
        "        'B-person': 9,\n",
        "        'I-person': 10,\n",
        "        'B-product': 11,\n",
        "        'I-product': 12,\n",
        "    }\n",
        "\n",
        "def IOB_to_NER (tokens, iob_tags):\n",
        "    ner_tags = []\n",
        "    for iob in iob_tags:\n",
        "        ner_tags.append([mapping[tag] for tag in iob])\n",
        "    return ner_tags\n",
        "\n",
        "ner_train = IOB_to_NER(tokens_train, tag_train)\n",
        "ner_dev = IOB_to_NER(tokens_dev, tag_dev)\n",
        "ner_test = IOB_to_NER(tokens_test, tag_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79is7WImatVn",
        "outputId": "91a8654c-7a74-4403-93bd-5e5f7734b65d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3394"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_dataset = datasets.Dataset.from_dict({\"id\": range(len(tokens_train)), \"tokens\": tokens_train, \"iob_tags\": tag_train, \"ner_tags\": ner_train})\n",
        "validation_dataset = datasets.Dataset.from_dict({\"id\": range(len(tokens_dev)), \"tokens\": tokens_dev, \"iob_tags\": tag_dev, \"ner_tags\": ner_dev})\n",
        "test_dataset = datasets.Dataset.from_dict({\"id\": range(len(tokens_test)), \"tokens\": tokens_test, \"iob_tags\": tag_test, \"ner_tags\": ner_test})\n",
        "\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "combined_datasets = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"validation\": validation_dataset,\n",
        "    \"test\": test_dataset\n",
        "})\n",
        "\n",
        "combined_datasets\n",
        "len(combined_datasets[\"train\"][\"tokens\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7jbh2OgatV_",
        "outputId": "3cb42a39-8c07-47a7-d46f-0212ee18a8af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@paulwalk It 's the view from where I 'm living for two weeks . Empire State Building = ESB . Pretty bad storm here last evening . \n",
            "O         O  O  O   O    O    O     O O  O      O   O   O     O B - l o c a t i o n      I - l o c a t i o n     I - l o c a t i o n        O B - l o c a t i o n   O O      O   O     O    O    O       O \n"
          ]
        }
      ],
      "source": [
        "# decoding and displaying the NER tags in a human-readable format\n",
        "words = combined_datasets[\"train\"][0][\"tokens\"]\n",
        "labels = combined_datasets[\"train\"][0][\"iob_tags\"]\n",
        "line1 = \"\"\n",
        "line2 = \"\"\n",
        "\n",
        "for word, labels in zip(words, labels):\n",
        "    max_length = max(len(word), max(len(label) for label in labels))\n",
        "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "    line2 += \" \".join(labels) + \" \" * (max_length - max(len(label) for label in labels) + 1)\n",
        "\n",
        "print(line1)\n",
        "print(line2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ6x4Rf9atWD"
      },
      "source": [
        "#### Align labels with tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3zY3pA2atWH",
        "outputId": "07b62182-5bbf-4eb5-a351-c08c6107349a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '@', 'p', '##aul', '##walk', 'It', \"'\", 's', 'the', 'view', 'from', 'where', 'I', \"'\", 'm', 'living', 'for', 'two', 'weeks', '.', 'Empire', 'State', 'Building', '=', 'E', '##SB', '.', 'Pretty', 'bad', 'storm', 'here', 'last', 'evening', '.', '[SEP]']\n",
            "[None, 0, 0, 0, 0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, None]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# tokenize a pre-tokenized input\n",
        "inputs = tokenizer(combined_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
        "print(inputs.tokens(), )\n",
        "print(inputs.word_ids(), )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Js6sP3natWI",
        "outputId": "4113cf1c-cdb5-41e2-8e83-4b7256636a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            # Start of a new word!\n",
        "            current_word = word_id\n",
        "            label = -100 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        elif word_id is None:\n",
        "            # Special token\n",
        "            new_labels.append(-100)\n",
        "        else:\n",
        "            # Same word as previous token\n",
        "            label = labels[word_id]\n",
        "            # # If the label is B-XXX we change it to I-XXX\n",
        "            if label % 2 == 1:\n",
        "                label += 1\n",
        "            new_labels.append(label)\n",
        "    return new_labels\n",
        "\n",
        "\n",
        "labels = combined_datasets[\"train\"][0][\"ner_tags\"]\n",
        "word_ids = inputs.word_ids()\n",
        "print(labels)\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367,
          "referenced_widgets": [
            "66c30cdb3aa44657b2c7f0546c137345",
            "f71e715b22654440a0e157979624d959",
            "396080ad56424e2e8094fff0f16001a4",
            "141f9a9a3bc9424bbab0a042651e9ed4",
            "4eb14dc4ab3e45d898f55b6d816d2061",
            "43af5012c74c4d1c874e97e0c4dcc692",
            "3b2543d22e104879a93e69383ca65ff6",
            "87214b32c36147879a0f6ae85b8d8e7d",
            "e55d14c4cffe4aecb0244a6f26c72f1e",
            "14af25fb8e1e49cd8e7936889367ebb7",
            "25ba9c7993484b7792e54330c5dcd233",
            "078f68171bd64041bb4020ba34ca3860",
            "dd0141117a9a4f8a96185d365abcd330",
            "3fce394e83ee4836a55b53fc7de6833f",
            "d52f0130d35f4b708ed7c9c4fadf5b63",
            "040b9dae0f9a4193b43b6991d8e63192",
            "16ab72e0ee524468bfcf1cb3c3f11a9a",
            "71f4c92cd7554d2f8f35a4e27c271a23",
            "f1f9995d34f642f4b49aa643ac1c2f16",
            "d7f20b0a0bdf49cf98165b7596fd6857",
            "0997c5d928d048d38747139cd3a087c3",
            "71e4840381a44292aee4124000d654ee",
            "2498330c872145bdbfd783bf6665b84e",
            "7b1c29e6a10a4a42a6ffb826f2560dec",
            "2eeeb7408d144c77a2b1cec0d657a489",
            "934f8da78c6e4954910eff36f774d39f",
            "87b7858e3e8a453f816cc81a7fd26a08",
            "87f83d84a73d450e8a8b974d0a3b807a",
            "ad7d0f9edf8442c9a8a1a73e799b5663",
            "90986e7454f94505865b7325afeb7f81",
            "3153c037487d472ea0ad0c1536875b46",
            "f4071b7d491841169a70bf0cf4c7e62a",
            "ec33de68434f4ead82d4a958d1ed7fef"
          ]
        },
        "id": "2qEbpOW7atWI",
        "outputId": "f5f35ac3-62b3-4deb-c68d-8a5f415a7507"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3394 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66c30cdb3aa44657b2c7f0546c137345"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1009 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "078f68171bd64041bb4020ba34ca3860"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1287 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2498330c872145bdbfd783bf6665b84e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3394\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1009\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1287\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
        "    )\n",
        "    all_labels = examples[\"ner_tags\"]\n",
        "    new_labels = []\n",
        "    for i, labels in enumerate(all_labels):\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "\n",
        "tokenized_datasets = combined_datasets.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=combined_datasets[\"train\"].column_names,\n",
        ")\n",
        "\n",
        "\n",
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muCXLSzoatWJ"
      },
      "source": [
        "### Fine-tuning the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xfbghSIFatWJ"
      },
      "outputs": [],
      "source": [
        "# from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "# data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(\n",
        "    tokenizer=tokenizer, return_tensors=\"tf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okNCxevNatWJ",
        "outputId": "e948d7f9-b40d-47a4-d53e-e6cdaea3b24a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'B-corporation', 'I-corporation', 'B-creative-work', 'I-creative-work', 'B-group', 'I-group', 'B-location', 'I-location', 'B-person', 'I-person', 'B-product', 'I-product']\n"
          ]
        }
      ],
      "source": [
        "label_names = ['O', 'B-corporation', 'I-corporation', 'B-creative-work', 'I-creative-work', 'B-group', 'I-group', 'B-location', 'I-location', 'B-person', 'I-person', 'B-product', 'I-product']\n",
        "print(label_names, )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqqmStkmatWJ"
      },
      "source": [
        "#### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxSezNoEbnrn",
        "outputId": "1a3c8d39-6b5f-4b0f-bac0-bfd1873ad422"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bXLAIPUPatWJ"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "metric = evaluate.load(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qMKqOxYXatWK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ral47lMaatWK",
        "outputId": "a10e267e-ddd5-491c-ccfb-d8f243759418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ],
      "source": [
        "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        ")\n",
        "\n",
        "tf_eval_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        ")\n",
        "\n",
        "tf_test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        ")\n",
        "\n",
        "tf_train_dataset32 = tokenized_datasets[\"train\"].to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=True,\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "tf_eval_dataset32 = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "tf_test_dataset32 = tokenized_datasets[\"test\"].to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=False,\n",
        "    batch_size=32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_AgNd11xatWK"
      },
      "outputs": [],
      "source": [
        "id2label = {i: label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqMSoABwatWK",
        "outputId": "d598d712-925c-4642-adf8-c523648d5168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModelForTokenClassification\n",
        "\n",
        "model = TFAutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2hZzhSuatWK"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmQCVrtDatWL"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n",
        "\n",
        "# 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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B28tbCsIatWL"
      },
      "outputs": [],
      "source": [
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "\n",
        "# Train in mixed-precision float16\n",
        "# Comment this line out if you're using a GPU that will not benefit from this\n",
        "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
        "# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\n",
        "# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\n",
        "num_epochs = 3\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=2e-5,\n",
        "    num_warmup_steps=0,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=0.01,\n",
        ")\n",
        "model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zm9mK0AatWM",
        "outputId": "3d32be1e-1227-49e9-e520-5f572e34aaa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner into local empty directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "213/213 [==============================] - 89s 268ms/step - loss: 0.3205\n",
            "Epoch 2/3\n",
            "213/213 [==============================] - 84s 394ms/step - loss: 0.1626\n",
            "Epoch 3/3\n",
            "213/213 [==============================] - 90s 421ms/step - loss: 0.1057\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c1ee6f4de10>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "\n",
        "callback = PushToHubCallback(output_dir=\"bert-finetuned-ner\", tokenizer=tokenizer)\n",
        "\n",
        "model.fit(\n",
        "    tf_train_dataset,\n",
        "    # validation_data=tf_eval_dataset,\n",
        "    callbacks=[callback],\n",
        "    epochs=num_epochs,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "for batch in tf_test_dataset:\n",
        "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    for prediction, label in zip(predictions, labels):\n",
        "        for predicted_idx, label_idx in zip(prediction, label):\n",
        "            if label_idx == -100:\n",
        "                continue\n",
        "            all_predictions.append(label_names[predicted_idx])\n",
        "            all_labels.append(label_names[label_idx])\n",
        "metric.compute(predictions=[all_predictions], references=[all_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq13X-ozdDKp",
        "outputId": "a4adf2db-0cc9-4dd3-bacf-ad81fb7fc17a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 66},\n",
              " 'creative-work': {'precision': 0.2,\n",
              "  'recall': 0.07746478873239436,\n",
              "  'f1': 0.11167512690355329,\n",
              "  'number': 142},\n",
              " 'group': {'precision': 0.2391304347826087,\n",
              "  'recall': 0.06666666666666667,\n",
              "  'f1': 0.10426540284360189,\n",
              "  'number': 165},\n",
              " 'location': {'precision': 0.3551912568306011,\n",
              "  'recall': 0.43333333333333335,\n",
              "  'f1': 0.3903903903903904,\n",
              "  'number': 150},\n",
              " 'person': {'precision': 0.6295081967213115,\n",
              "  'recall': 0.44755244755244755,\n",
              "  'f1': 0.5231607629427792,\n",
              "  'number': 429},\n",
              " 'product': {'precision': 0.047058823529411764,\n",
              "  'recall': 0.031496062992125984,\n",
              "  'f1': 0.03773584905660377,\n",
              "  'number': 127},\n",
              " 'overall_precision': 0.41253644314868804,\n",
              " 'overall_recall': 0.2622798887859129,\n",
              " 'overall_f1': 0.3206798866855524,\n",
              " 'overall_accuracy': 0.9319597989949748}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from sklearn.model_selection import ParameterGrid\n",
        "# from transformers import TFAutoModelForTokenClassification, create_optimizer\n",
        "# from transformers.keras_callbacks import PushToHubCallback\n",
        "# import tensorflow as tf\n",
        "# import evaluate\n",
        "\n",
        "# metric = evaluate.load(\"seqeval\")\n",
        "\n",
        "# # Define your tokenized_datasets, data_collator, label_names, etc.\n",
        "\n",
        "# learning_rates = [1e-5, 1e-5, 5e-6]\n",
        "# batch_sizes = [16, 32]\n",
        "\n",
        "# # Instantiate the metric (e.g., seqeval) if not already done\n",
        "# # metric = evaluate.load(\"seqeval\")\n",
        "\n",
        "# results = []\n",
        "\n",
        "# for batch_size in batch_sizes:\n",
        "#     for learning_rate in learning_rates:\n",
        "#         # Train in mixed-precision float16\n",
        "#         # Comment this line out if you're using a GPU that will not benefit from this\n",
        "#         tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "#         num_epochs = 3\n",
        "\n",
        "#         # Create the TF datasets for the given batch size\n",
        "#         tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
        "#             columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "#             collate_fn=data_collator,\n",
        "#             shuffle=True,\n",
        "#             batch_size=batch_size,\n",
        "#         )\n",
        "\n",
        "#         tf_eval_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
        "#             columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "#             collate_fn=data_collator,\n",
        "#             shuffle=False,\n",
        "#             batch_size=batch_size,\n",
        "#         )\n",
        "\n",
        "#         tf_test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
        "#             columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "#             collate_fn=data_collator,\n",
        "#             shuffle=False,\n",
        "#             batch_size=batch_size,\n",
        "#         )\n",
        "\n",
        "#         model = TFAutoModelForTokenClassification.from_pretrained(\n",
        "#             model_checkpoint,\n",
        "#             id2label=id2label,\n",
        "#             label2id=label2id,\n",
        "#         )\n",
        "\n",
        "#         # optimizer with AdamW\n",
        "#         num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "#         optimizer, schedule = create_optimizer(\n",
        "#             init_lr=learning_rate,\n",
        "#             num_warmup_steps=0,\n",
        "#             num_train_steps=num_train_steps,\n",
        "#             weight_decay_rate=0.01,\n",
        "#         )\n",
        "\n",
        "#         model.compile(optimizer=optimizer)\n",
        "\n",
        "#         callback = PushToHubCallback(output_dir=f\"bert-finetuned-ner_lr{learning_rate}_bs{batch_size}\", tokenizer=tokenizer)\n",
        "\n",
        "#         history = model.fit(\n",
        "#             tf_train_dataset,\n",
        "#             validation_data=tf_eval_dataset,  # Use the dev set for validation\n",
        "#             callbacks=[callback],\n",
        "#             epochs=num_epochs,\n",
        "#         )\n",
        "\n",
        "#         all_predictions = []\n",
        "#         all_labels = []\n",
        "\n",
        "#         for batch in tf_test_dataset:\n",
        "#             logits = model.predict_on_batch(batch)[\"logits\"]\n",
        "#             labels = batch[\"labels\"]\n",
        "#             predictions = np.argmax(logits, axis=-1)\n",
        "#             for prediction, label in zip(predictions, labels):\n",
        "#                 for predicted_idx, label_idx in zip(prediction, label):\n",
        "#                     if label_idx != -100:\n",
        "#                         all_predictions.append(predicted_idx)\n",
        "#                         all_labels.append(label_idx)\n",
        "\n",
        "#         # Use metric.compute() for NER evaluation\n",
        "#         report = metric.compute(predictions=[all_predictions], references=[all_labels])\n",
        "\n",
        "#         print(f\"Learning Rate: {learning_rate}, Batch Size: {batch_size}\")\n",
        "#         print(report)\n",
        "\n",
        "#         results.append({\n",
        "#             'learning_rate': learning_rate,\n",
        "#             'batch_size': batch_size,\n",
        "#             'classification_report': report,\n",
        "#         })\n"
      ],
      "metadata": {
        "id": "EXk6TTD2iKY4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "import numpy as np\n",
        "# Train in mixed-precision float16\n",
        "# Comment this line out if you're using a GPU that will not benefit from this\n",
        "# tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "learning_rates = [1e-5, 3e-5, 5e-6]\n",
        "\n",
        "num_epochs = 3\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=learning_rates[0],\n",
        "    num_warmup_steps=0,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=0.01,\n",
        ")\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "\n",
        "callback = PushToHubCallback(output_dir=\"bert-finetuned-ner-1e-5-b16\", tokenizer=tokenizer)\n",
        "\n",
        "model.fit(\n",
        "    tf_train_dataset,\n",
        "    validation_data=tf_eval_dataset,\n",
        "    callbacks=[callback],\n",
        "    epochs=num_epochs,\n",
        ")\n",
        "\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "for batch in tf_test_dataset:\n",
        "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    for prediction, label in zip(predictions, labels):\n",
        "        for predicted_idx, label_idx in zip(prediction, label):\n",
        "            if label_idx == -100:\n",
        "                continue\n",
        "            all_predictions.append(label_names[predicted_idx])\n",
        "            all_labels.append(label_names[label_idx])\n",
        "metric.compute(predictions=[all_predictions], references=[all_labels])\n",
        "\n"
      ],
      "metadata": {
        "id": "IzKvdZ-KbaiX",
        "outputId": "e3fe379c-8b1c-4e31-8854-268d300298a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/bert-finetuned-ner-1e-5-b16 is already a clone of https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-1e-5-b16. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/bert-finetuned-ner-1e-5-b16 is already a clone of https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-1e-5-b16. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "213/213 [==============================] - 95s 331ms/step - loss: 0.0915 - val_loss: 0.3494\n",
            "Epoch 2/3\n",
            "213/213 [==============================] - ETA: 0s - loss: 0.0684"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Several commits (2) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r213/213 [==============================] - 98s 459ms/step - loss: 0.0684 - val_loss: 0.3594\n",
            "Epoch 3/3\n",
            "213/213 [==============================] - ETA: 0s - loss: 0.0521"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Several commits (3) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (3) will be pushed upstream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r213/213 [==============================] - 99s 467ms/step - loss: 0.0521 - val_loss: 0.3846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'corporation': {'precision': 0.16666666666666666,\n",
              "  'recall': 0.24242424242424243,\n",
              "  'f1': 0.19753086419753085,\n",
              "  'number': 66},\n",
              " 'creative-work': {'precision': 0.2653061224489796,\n",
              "  'recall': 0.18309859154929578,\n",
              "  'f1': 0.21666666666666667,\n",
              "  'number': 142},\n",
              " 'group': {'precision': 0.39344262295081966,\n",
              "  'recall': 0.14545454545454545,\n",
              "  'f1': 0.21238938053097342,\n",
              "  'number': 165},\n",
              " 'location': {'precision': 0.5470085470085471,\n",
              "  'recall': 0.4266666666666667,\n",
              "  'f1': 0.4794007490636704,\n",
              "  'number': 150},\n",
              " 'person': {'precision': 0.7014925373134329,\n",
              "  'recall': 0.4382284382284382,\n",
              "  'f1': 0.539454806312769,\n",
              "  'number': 429},\n",
              " 'product': {'precision': 0.10666666666666667,\n",
              "  'recall': 0.06299212598425197,\n",
              "  'f1': 0.0792079207920792,\n",
              "  'number': 127},\n",
              " 'overall_precision': 0.45594405594405596,\n",
              " 'overall_recall': 0.30213160333642264,\n",
              " 'overall_f1': 0.3634336677814939,\n",
              " 'overall_accuracy': 0.9345979899497487}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "import numpy as np\n",
        "# Train in mixed-precision float16\n",
        "# Comment this line out if you're using a GPU that will not benefit from this\n",
        "# tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "learning_rates = [1e-5, 3e-5, 5e-6]\n",
        "\n",
        "num_epochs = 3\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=learning_rates[1],\n",
        "    num_warmup_steps=0,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=0.01,\n",
        ")\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "\n",
        "callback = PushToHubCallback(output_dir=\"bert-finetuned-ner-3e-5-b16\", tokenizer=tokenizer)\n",
        "\n",
        "model.fit(\n",
        "    tf_train_dataset,\n",
        "    validation_data=tf_eval_dataset,\n",
        "    callbacks=[callback],\n",
        "    epochs=num_epochs,\n",
        ")\n",
        "\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "for batch in tf_test_dataset:\n",
        "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    for prediction, label in zip(predictions, labels):\n",
        "        for predicted_idx, label_idx in zip(prediction, label):\n",
        "            if label_idx == -100:\n",
        "                continue\n",
        "            all_predictions.append(label_names[predicted_idx])\n",
        "            all_labels.append(label_names[label_idx])\n",
        "metric.compute(predictions=[all_predictions], references=[all_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5G8x-vrGwFS",
        "outputId": "b530df5d-630f-43b7-d763-0b9df072b08d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/bert-finetuned-ner-3e-5-b16 is already a clone of https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-3e-5-b16. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/bert-finetuned-ner-3e-5-b16 is already a clone of https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-3e-5-b16. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "213/213 [==============================] - 86s 317ms/step - loss: 0.0693 - val_loss: 0.4033\n",
            "Epoch 2/3\n",
            "213/213 [==============================] - ETA: 0s - loss: 0.0403"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Several commits (2) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r213/213 [==============================] - 93s 437ms/step - loss: 0.0403 - val_loss: 0.3976\n",
            "Epoch 3/3\n",
            "213/213 [==============================] - ETA: 0s - loss: 0.0240"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Several commits (3) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (3) will be pushed upstream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r213/213 [==============================] - 107s 501ms/step - loss: 0.0240 - val_loss: 0.3907\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'corporation': {'precision': 0.20833333333333334,\n",
              "  'recall': 0.22727272727272727,\n",
              "  'f1': 0.21739130434782608,\n",
              "  'number': 66},\n",
              " 'creative-work': {'precision': 0.32978723404255317,\n",
              "  'recall': 0.21830985915492956,\n",
              "  'f1': 0.2627118644067797,\n",
              "  'number': 142},\n",
              " 'group': {'precision': 0.5,\n",
              "  'recall': 0.19393939393939394,\n",
              "  'f1': 0.2794759825327511,\n",
              "  'number': 165},\n",
              " 'location': {'precision': 0.5636363636363636,\n",
              "  'recall': 0.41333333333333333,\n",
              "  'f1': 0.47692307692307695,\n",
              "  'number': 150},\n",
              " 'person': {'precision': 0.7529411764705882,\n",
              "  'recall': 0.44755244755244755,\n",
              "  'f1': 0.5614035087719298,\n",
              "  'number': 429},\n",
              " 'product': {'precision': 0.2,\n",
              "  'recall': 0.14173228346456693,\n",
              "  'f1': 0.1658986175115207,\n",
              "  'number': 127},\n",
              " 'overall_precision': 0.5109489051094891,\n",
              " 'overall_recall': 0.3243744207599629,\n",
              " 'overall_f1': 0.39682539682539686,\n",
              " 'overall_accuracy': 0.9351005025125628}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "import numpy as np\n",
        "# Train in mixed-precision float16\n",
        "# Comment this line out if you're using a GPU that will not benefit from this\n",
        "# tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "learning_rates = [1e-5, 3e-5, 5e-6]\n",
        "\n",
        "num_epochs = 3\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=learning_rates[2],\n",
        "    num_warmup_steps=0,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=0.01,\n",
        ")\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "\n",
        "callback = PushToHubCallback(output_dir=\"bert-finetuned-ner-5e-5-b16\", tokenizer=tokenizer)\n",
        "\n",
        "model.fit(\n",
        "    tf_train_dataset,\n",
        "    validation_data=tf_eval_dataset,\n",
        "    callbacks=[callback],\n",
        "    epochs=num_epochs,\n",
        ")\n",
        "\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "for batch in tf_test_dataset:\n",
        "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    for prediction, label in zip(predictions, labels):\n",
        "        for predicted_idx, label_idx in zip(prediction, label):\n",
        "            if label_idx == -100:\n",
        "                continue\n",
        "            all_predictions.append(label_names[predicted_idx])\n",
        "            all_labels.append(label_names[label_idx])\n",
        "metric.compute(predictions=[all_predictions], references=[all_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_g_WmYUG41H",
        "outputId": "7ccb5da1-f477-4aaf-d5fb-417dd23752d6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/bert-finetuned-ner-5e-5-b16 is already a clone of https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-5e-5-b16. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/bert-finetuned-ner-5e-5-b16 is already a clone of https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-5e-5-b16. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "213/213 [==============================] - 88s 327ms/step - loss: 0.0199 - val_loss: 0.4218\n",
            "Epoch 2/3\n",
            "213/213 [==============================] - ETA: 0s - loss: 0.0155"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Several commits (2) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r213/213 [==============================] - 121s 567ms/step - loss: 0.0155 - val_loss: 0.4325\n",
            "Epoch 3/3\n",
            "213/213 [==============================] - ETA: 0s - loss: 0.0140"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Several commits (3) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (3) will be pushed upstream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r213/213 [==============================] - 103s 485ms/step - loss: 0.0140 - val_loss: 0.4387\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'corporation': {'precision': 0.20238095238095238,\n",
              "  'recall': 0.25757575757575757,\n",
              "  'f1': 0.22666666666666666,\n",
              "  'number': 66},\n",
              " 'creative-work': {'precision': 0.3563218390804598,\n",
              "  'recall': 0.21830985915492956,\n",
              "  'f1': 0.2707423580786026,\n",
              "  'number': 142},\n",
              " 'group': {'precision': 0.5166666666666667,\n",
              "  'recall': 0.18787878787878787,\n",
              "  'f1': 0.27555555555555555,\n",
              "  'number': 165},\n",
              " 'location': {'precision': 0.5344827586206896,\n",
              "  'recall': 0.41333333333333333,\n",
              "  'f1': 0.46616541353383456,\n",
              "  'number': 150},\n",
              " 'person': {'precision': 0.7642276422764228,\n",
              "  'recall': 0.4382284382284382,\n",
              "  'f1': 0.557037037037037,\n",
              "  'number': 429},\n",
              " 'product': {'precision': 0.17391304347826086,\n",
              "  'recall': 0.12598425196850394,\n",
              "  'f1': 0.1461187214611872,\n",
              "  'number': 127},\n",
              " 'overall_precision': 0.5036496350364964,\n",
              " 'overall_recall': 0.31974050046339203,\n",
              " 'overall_f1': 0.391156462585034,\n",
              " 'overall_accuracy': 0.9343718592964824}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "import numpy as np\n",
        "# Train in mixed-precision float16\n",
        "# Comment this line out if you're using a GPU that will not benefit from this\n",
        "# tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "learning_rates = [1e-5, 3e-5, 5e-6]\n",
        "\n",
        "num_epochs = 3\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=learning_rates[0],\n",
        "    num_warmup_steps=0,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=0.01,\n",
        ")\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "\n",
        "callback = PushToHubCallback(output_dir=\"bert-finetuned-ner-1e-5-b32\", tokenizer=tokenizer)\n",
        "\n",
        "model.fit(\n",
        "    tf_train_dataset32,\n",
        "    validation_data=tf_eval_dataset32,\n",
        "    callbacks=[callback],\n",
        "    epochs=num_epochs,\n",
        ")\n",
        "\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "for batch in tf_test_dataset32:\n",
        "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    for prediction, label in zip(predictions, labels):\n",
        "        for predicted_idx, label_idx in zip(prediction, label):\n",
        "            if label_idx == -100:\n",
        "                continue\n",
        "            all_predictions.append(label_names[predicted_idx])\n",
        "            all_labels.append(label_names[label_idx])\n",
        "metric.compute(predictions=[all_predictions], references=[all_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT_hzToWG-yb",
        "outputId": "c9d37cc1-2a7d-4bfc-d989-b8f97fd180e3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/bert-finetuned-ner-1e-5-b32 is already a clone of https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-1e-5-b32. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/bert-finetuned-ner-1e-5-b32 is already a clone of https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-1e-5-b32. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "107/107 [==============================] - 92s 669ms/step - loss: 0.0146 - val_loss: 0.4346\n",
            "Epoch 2/3\n",
            "107/107 [==============================] - ETA: 0s - loss: 0.0121"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Several commits (2) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r107/107 [==============================] - 100s 940ms/step - loss: 0.0121 - val_loss: 0.4452\n",
            "Epoch 3/3\n",
            "107/107 [==============================] - ETA: 0s - loss: 0.0093"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Several commits (3) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (3) will be pushed upstream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r107/107 [==============================] - 96s 906ms/step - loss: 0.0093 - val_loss: 0.4913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'corporation': {'precision': 0.18478260869565216,\n",
              "  'recall': 0.25757575757575757,\n",
              "  'f1': 0.21518987341772153,\n",
              "  'number': 66},\n",
              " 'creative-work': {'precision': 0.4230769230769231,\n",
              "  'recall': 0.2323943661971831,\n",
              "  'f1': 0.3,\n",
              "  'number': 142},\n",
              " 'group': {'precision': 0.4696969696969697,\n",
              "  'recall': 0.18787878787878787,\n",
              "  'f1': 0.2683982683982684,\n",
              "  'number': 165},\n",
              " 'location': {'precision': 0.5803571428571429,\n",
              "  'recall': 0.43333333333333335,\n",
              "  'f1': 0.4961832061068702,\n",
              "  'number': 150},\n",
              " 'person': {'precision': 0.7649572649572649,\n",
              "  'recall': 0.4172494172494173,\n",
              "  'f1': 0.5399698340874812,\n",
              "  'number': 429},\n",
              " 'product': {'precision': 0.18823529411764706,\n",
              "  'recall': 0.12598425196850394,\n",
              "  'f1': 0.1509433962264151,\n",
              "  'number': 127},\n",
              " 'overall_precision': 0.5112443778110944,\n",
              " 'overall_recall': 0.3160333642261353,\n",
              " 'overall_f1': 0.3906071019473082,\n",
              " 'overall_accuracy': 0.9342462311557789}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "import numpy as np\n",
        "# Train in mixed-precision float16\n",
        "# Comment this line out if you're using a GPU that will not benefit from this\n",
        "# tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "learning_rates = [1e-5, 3e-5, 5e-6]\n",
        "\n",
        "num_epochs = 3\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=learning_rates[1],\n",
        "    num_warmup_steps=0,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=0.01,\n",
        ")\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "\n",
        "callback = PushToHubCallback(output_dir=\"bert-finetuned-ner-3e-5-32\", tokenizer=tokenizer)\n",
        "\n",
        "model.fit(\n",
        "    tf_train_dataset32,\n",
        "    validation_data=tf_eval_dataset32,\n",
        "    callbacks=[callback],\n",
        "    epochs=num_epochs,\n",
        ")\n",
        "\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "for batch in tf_test_dataset32:\n",
        "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    for prediction, label in zip(predictions, labels):\n",
        "        for predicted_idx, label_idx in zip(prediction, label):\n",
        "            if label_idx == -100:\n",
        "                continue\n",
        "            all_predictions.append(label_names[predicted_idx])\n",
        "            all_labels.append(label_names[label_idx])\n",
        "metric.compute(predictions=[all_predictions], references=[all_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4d7tQDsHgTk",
        "outputId": "30bfacdb-ef49-4651-c1c1-776dead506a5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/bert-finetuned-ner-3e-5-32 is already a clone of https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-3e-5-32. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/bert-finetuned-ner-3e-5-32 is already a clone of https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-3e-5-32. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "107/107 [==============================] - 84s 612ms/step - loss: 0.0140 - val_loss: 0.5003\n",
            "Epoch 2/3\n",
            "107/107 [==============================] - ETA: 0s - loss: 0.0119"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Several commits (2) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r107/107 [==============================] - 109s 1s/step - loss: 0.0119 - val_loss: 0.4489\n",
            "Epoch 3/3\n",
            "107/107 [==============================] - ETA: 0s - loss: 0.0097"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Several commits (3) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (3) will be pushed upstream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r107/107 [==============================] - 97s 915ms/step - loss: 0.0097 - val_loss: 0.4629\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'corporation': {'precision': 0.25,\n",
              "  'recall': 0.22727272727272727,\n",
              "  'f1': 0.23809523809523808,\n",
              "  'number': 66},\n",
              " 'creative-work': {'precision': 0.3684210526315789,\n",
              "  'recall': 0.19718309859154928,\n",
              "  'f1': 0.2568807339449541,\n",
              "  'number': 142},\n",
              " 'group': {'precision': 0.5625,\n",
              "  'recall': 0.16363636363636364,\n",
              "  'f1': 0.2535211267605634,\n",
              "  'number': 165},\n",
              " 'location': {'precision': 0.5666666666666667,\n",
              "  'recall': 0.4533333333333333,\n",
              "  'f1': 0.5037037037037037,\n",
              "  'number': 150},\n",
              " 'person': {'precision': 0.73828125,\n",
              "  'recall': 0.4405594405594406,\n",
              "  'f1': 0.5518248175182482,\n",
              "  'number': 429},\n",
              " 'product': {'precision': 0.171875,\n",
              "  'recall': 0.1732283464566929,\n",
              "  'f1': 0.1725490196078431,\n",
              "  'number': 127},\n",
              " 'overall_precision': 0.5072674418604651,\n",
              " 'overall_recall': 0.32344763670064874,\n",
              " 'overall_f1': 0.39501980758347477,\n",
              " 'overall_accuracy': 0.9351005025125628}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "import numpy as np\n",
        "# Train in mixed-precision float16\n",
        "# Comment this line out if you're using a GPU that will not benefit from this\n",
        "# tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "learning_rates = [1e-5, 3e-5, 5e-6]\n",
        "\n",
        "num_epochs = 3\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=learning_rates[2],\n",
        "    num_warmup_steps=0,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=0.01,\n",
        ")\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "\n",
        "callback = PushToHubCallback(output_dir=\"bert-finetuned-ner-5e-5-32\", tokenizer=tokenizer)\n",
        "\n",
        "model.fit(\n",
        "    tf_train_dataset32,\n",
        "    validation_data=tf_eval_dataset32,\n",
        "    callbacks=[callback],\n",
        "    epochs=num_epochs,\n",
        ")\n",
        "\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "for batch in tf_test_dataset32:\n",
        "    logits = model.predict_on_batch(batch)[\"logits\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    for prediction, label in zip(predictions, labels):\n",
        "        for predicted_idx, label_idx in zip(prediction, label):\n",
        "            if label_idx == -100:\n",
        "                continue\n",
        "            all_predictions.append(label_names[predicted_idx])\n",
        "            all_labels.append(label_names[label_idx])\n",
        "metric.compute(predictions=[all_predictions], references=[all_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al_RRMj0HnYW",
        "outputId": "c725c711-9389-4b6b-d4e1-4d747df26595"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/bert-finetuned-ner-5e-5-32 is already a clone of https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-5e-5-32. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/bert-finetuned-ner-5e-5-32 is already a clone of https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-5e-5-32. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "107/107 [==============================] - 90s 671ms/step - loss: 0.0047 - val_loss: 0.5226\n",
            "Epoch 2/3\n",
            "107/107 [==============================] - ETA: 0s - loss: 0.0033"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Several commits (2) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r107/107 [==============================] - 103s 968ms/step - loss: 0.0033 - val_loss: 0.5440\n",
            "Epoch 3/3\n",
            "107/107 [==============================] - ETA: 0s - loss: 0.0033"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Several commits (3) will be pushed upstream.\n",
            "WARNING:huggingface_hub.repository:Several commits (3) will be pushed upstream.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r107/107 [==============================] - 106s 993ms/step - loss: 0.0033 - val_loss: 0.5445\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'corporation': {'precision': 0.2112676056338028,\n",
              "  'recall': 0.22727272727272727,\n",
              "  'f1': 0.21897810218978103,\n",
              "  'number': 66},\n",
              " 'creative-work': {'precision': 0.40963855421686746,\n",
              "  'recall': 0.23943661971830985,\n",
              "  'f1': 0.3022222222222222,\n",
              "  'number': 142},\n",
              " 'group': {'precision': 0.4714285714285714,\n",
              "  'recall': 0.2,\n",
              "  'f1': 0.28085106382978725,\n",
              "  'number': 165},\n",
              " 'location': {'precision': 0.5739130434782609,\n",
              "  'recall': 0.44,\n",
              "  'f1': 0.49811320754716987,\n",
              "  'number': 150},\n",
              " 'person': {'precision': 0.758893280632411,\n",
              "  'recall': 0.44755244755244755,\n",
              "  'f1': 0.563049853372434,\n",
              "  'number': 429},\n",
              " 'product': {'precision': 0.19101123595505617,\n",
              "  'recall': 0.13385826771653545,\n",
              "  'f1': 0.1574074074074074,\n",
              "  'number': 127},\n",
              " 'overall_precision': 0.5242290748898678,\n",
              " 'overall_recall': 0.33086190917516217,\n",
              " 'overall_f1': 0.40568181818181814,\n",
              " 'overall_accuracy': 0.9350502512562814}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import TFAutoModelForTokenClassification\n",
        "# from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "# model_checkpoint2 = \"PelagiaKalpakidou/bert-finetuned-ner-5e-5-32\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint2)\n",
        "\n",
        "# tf_train_dataset32 = tokenized_datasets[\"train\"].to_tf_dataset(\n",
        "#     columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "#     collate_fn=data_collator,\n",
        "#     shuffle=True,\n",
        "#     batch_size=32,\n",
        "# )\n",
        "\n",
        "# tf_eval_dataset32 = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
        "#     columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "#     collate_fn=data_collator,\n",
        "#     shuffle=False,\n",
        "#     batch_size=32,\n",
        "# )\n",
        "\n",
        "# tf_test_dataset32 = tokenized_datasets[\"test\"].to_tf_dataset(\n",
        "#     columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
        "#     collate_fn=data_collator,\n",
        "#     shuffle=False,\n",
        "#     batch_size=32,\n",
        "# )\n",
        "\n",
        "# model = TFAutoModelForTokenClassification.from_pretrained(\n",
        "#     model_checkpoint2,\n",
        "#     id2label=id2label,\n",
        "#     label2id=label2id,\n",
        "# )\n",
        "\n",
        "# all_predictions = []\n",
        "# all_labels = []\n",
        "# for batch in tf_test_dataset32:\n",
        "#     logits = model.predict_on_batch(batch)[\"logits\"]\n",
        "#     labels = batch[\"labels\"]\n",
        "#     predictions = np.argmax(logits, axis=-1)\n",
        "#     for prediction, label in zip(predictions, labels):\n",
        "#         for predicted_idx, label_idx in zip(prediction, label):\n",
        "#             if label_idx == -100:\n",
        "#                 continue\n",
        "#             all_predictions.append(label_names[predicted_idx])\n",
        "#             all_labels.append(label_names[label_idx])\n",
        "\n",
        "# # Compute classification report (precision, recall, F1-score)\n",
        "# report = classification_report(all_labels, all_predictions)\n",
        "# print(report)\n",
        "\n",
        "# micro_avg_f1 = f1_score(all_labels, all_predictions, average='micro')\n",
        "# print(\"Micro-average F1 score:\", micro_avg_f1)\n",
        "\n",
        "# # Calculate macro-average F1 score\n",
        "# macro_avg_f1 = f1_score(all_labels, all_predictions, average='macro')\n",
        "# print(\"Macro-average F1 score:\", macro_avg_f1)"
      ],
      "metadata": {
        "id": "LR6eJnw8ZuHm",
        "outputId": "9531b8d1-6d85-4be7-f391-29e2964220ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-5e-5-32/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1233\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1607\u001b[0m     )\n\u001b[0;32m-> 1608\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{response.status_code} Client Error.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"Entry Not Found for url: {response.url}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEntryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-654a7883-02d3b92e0fc2335223743c8f;80a88dfa-cf11-42cb-b187-099ae3466378)\n\nEntry Not Found for url: https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-5e-5-32/resolve/main/config.json.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-51cdf744ef5f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_checkpoint2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"PelagiaKalpakidou/bert-finetuned-ner-5e-5-32\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m tf_train_dataset32 = tokenized_datasets[\"train\"].to_tf_dataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_tokenizer_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 config = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    734\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mcode_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    678\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrevision\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mrevision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"main\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} does not appear to have a file named {full_filename}. Checkout \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;34mf\"'https://huggingface.co/{path_or_repo_id}/{revision}' for available files.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: PelagiaKalpakidou/bert-finetuned-ner-5e-5-32 does not appear to have a file named config.json. Checkout 'https://huggingface.co/PelagiaKalpakidou/bert-finetuned-ner-5e-5-32/main' for available files."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "66c30cdb3aa44657b2c7f0546c137345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f71e715b22654440a0e157979624d959",
              "IPY_MODEL_396080ad56424e2e8094fff0f16001a4",
              "IPY_MODEL_141f9a9a3bc9424bbab0a042651e9ed4"
            ],
            "layout": "IPY_MODEL_4eb14dc4ab3e45d898f55b6d816d2061"
          }
        },
        "f71e715b22654440a0e157979624d959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43af5012c74c4d1c874e97e0c4dcc692",
            "placeholder": "​",
            "style": "IPY_MODEL_3b2543d22e104879a93e69383ca65ff6",
            "value": "Map: 100%"
          }
        },
        "396080ad56424e2e8094fff0f16001a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87214b32c36147879a0f6ae85b8d8e7d",
            "max": 3394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e55d14c4cffe4aecb0244a6f26c72f1e",
            "value": 3394
          }
        },
        "141f9a9a3bc9424bbab0a042651e9ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14af25fb8e1e49cd8e7936889367ebb7",
            "placeholder": "​",
            "style": "IPY_MODEL_25ba9c7993484b7792e54330c5dcd233",
            "value": " 3394/3394 [00:01&lt;00:00, 2447.19 examples/s]"
          }
        },
        "4eb14dc4ab3e45d898f55b6d816d2061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43af5012c74c4d1c874e97e0c4dcc692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2543d22e104879a93e69383ca65ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87214b32c36147879a0f6ae85b8d8e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e55d14c4cffe4aecb0244a6f26c72f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14af25fb8e1e49cd8e7936889367ebb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25ba9c7993484b7792e54330c5dcd233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "078f68171bd64041bb4020ba34ca3860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd0141117a9a4f8a96185d365abcd330",
              "IPY_MODEL_3fce394e83ee4836a55b53fc7de6833f",
              "IPY_MODEL_d52f0130d35f4b708ed7c9c4fadf5b63"
            ],
            "layout": "IPY_MODEL_040b9dae0f9a4193b43b6991d8e63192"
          }
        },
        "dd0141117a9a4f8a96185d365abcd330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16ab72e0ee524468bfcf1cb3c3f11a9a",
            "placeholder": "​",
            "style": "IPY_MODEL_71f4c92cd7554d2f8f35a4e27c271a23",
            "value": "Map: 100%"
          }
        },
        "3fce394e83ee4836a55b53fc7de6833f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f9995d34f642f4b49aa643ac1c2f16",
            "max": 1009,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7f20b0a0bdf49cf98165b7596fd6857",
            "value": 1009
          }
        },
        "d52f0130d35f4b708ed7c9c4fadf5b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0997c5d928d048d38747139cd3a087c3",
            "placeholder": "​",
            "style": "IPY_MODEL_71e4840381a44292aee4124000d654ee",
            "value": " 1009/1009 [00:00&lt;00:00, 6244.42 examples/s]"
          }
        },
        "040b9dae0f9a4193b43b6991d8e63192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16ab72e0ee524468bfcf1cb3c3f11a9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71f4c92cd7554d2f8f35a4e27c271a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1f9995d34f642f4b49aa643ac1c2f16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7f20b0a0bdf49cf98165b7596fd6857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0997c5d928d048d38747139cd3a087c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e4840381a44292aee4124000d654ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2498330c872145bdbfd783bf6665b84e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b1c29e6a10a4a42a6ffb826f2560dec",
              "IPY_MODEL_2eeeb7408d144c77a2b1cec0d657a489",
              "IPY_MODEL_934f8da78c6e4954910eff36f774d39f"
            ],
            "layout": "IPY_MODEL_87b7858e3e8a453f816cc81a7fd26a08"
          }
        },
        "7b1c29e6a10a4a42a6ffb826f2560dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87f83d84a73d450e8a8b974d0a3b807a",
            "placeholder": "​",
            "style": "IPY_MODEL_ad7d0f9edf8442c9a8a1a73e799b5663",
            "value": "Map: 100%"
          }
        },
        "2eeeb7408d144c77a2b1cec0d657a489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90986e7454f94505865b7325afeb7f81",
            "max": 1287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3153c037487d472ea0ad0c1536875b46",
            "value": 1287
          }
        },
        "934f8da78c6e4954910eff36f774d39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4071b7d491841169a70bf0cf4c7e62a",
            "placeholder": "​",
            "style": "IPY_MODEL_ec33de68434f4ead82d4a958d1ed7fef",
            "value": " 1287/1287 [00:00&lt;00:00, 5290.11 examples/s]"
          }
        },
        "87b7858e3e8a453f816cc81a7fd26a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87f83d84a73d450e8a8b974d0a3b807a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad7d0f9edf8442c9a8a1a73e799b5663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90986e7454f94505865b7325afeb7f81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3153c037487d472ea0ad0c1536875b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4071b7d491841169a70bf0cf4c7e62a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec33de68434f4ead82d4a958d1ed7fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}